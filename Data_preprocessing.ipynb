{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing: Loading and Annotating Flow Cytometry Files\n",
    "\n",
    "This script is part of the **CHOFlow** repository and focuses on preprocessing flow cytometry data from CHO cell experiments. The main functionalities of this script include:\n",
    "\n",
    "1. **Loading `.fcs` Files**: Automatically retrieves and processes raw data from `.fcs` files stored in structured folders.\n",
    "2. **Annotating Data**: Adds experimental metadata such as `Time`, `Clone`, `Replicate`, and `Sample_Type` to each event in the dataset.\n",
    "3. **Sample Type Classification**: Uses conditions and regular expressions to categorize data as `ST` (staining control), `Control`, or `Sample`.\n",
    "4. **Exporting Processed Data**: Consolidates all processed data into a single CSV file for downstream analysis.\n",
    "\n",
    "### Output\n",
    "The final output is a `processed_data.csv` file containing the annotated flow cytometry data, ready for visualization and analysis.\n",
    "\n",
    "### Requirements\n",
    "- Python 3.7+\n",
    "- `pandas`\n",
    "- `numpy`\n",
    "- `FlowKit`\n",
    "\n",
    "This script serves as the foundational step in automating and streamlining the analysis of CHO cell flow cytometry data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import flowkit as fk\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main directory where the script is executed\n",
    "main_directory = os.getcwd()\n",
    "\n",
    "# Retrieve all subdirectories representing time points in the main directory\n",
    "time_folders = [\n",
    "    folder for folder in os.listdir(main_directory)\n",
    "    if os.path.isdir(os.path.join(main_directory, folder))\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Process each time folder to load data and assign metadata\n",
    "for folder in time_folders:\n",
    "    # Build the path to the \"JC1\" subfolder\n",
    "    jc1_folder_path = os.path.join(main_directory, folder, \"JC1\")\n",
    "    \n",
    "    # Skip if the \"JC1\" folder does not exist\n",
    "    if not os.path.isdir(jc1_folder_path):\n",
    "        continue\n",
    "\n",
    "    # List all .fcs files in the \"JC1\" folder\n",
    "    fcs_files = [file for file in os.listdir(jc1_folder_path) if file.endswith(\".fcs\")]\n",
    "\n",
    "    # Process each .fcs file and add metadata\n",
    "    for file in fcs_files:\n",
    "        file_path = os.path.join(jc1_folder_path, file)\n",
    "        \n",
    "        # Load the .fcs file using FlowKit\n",
    "        sample = fk.Sample(file_path)\n",
    "\n",
    "        # Retrieve raw event data as a DataFrame\n",
    "        events_df = pd.DataFrame(\n",
    "            sample.get_events(source=\"raw\"),\n",
    "            columns=sample.channels[\"pnn\"]\n",
    "        )\n",
    "\n",
    "        # Add file and folder metadata\n",
    "        events_df[\"File_Name\"] = file  # Source file name\n",
    "        events_df[\"Folder\"] = folder  # Parent folder name\n",
    "        events_df[\"Time\"] = folder[-1]  # Extract the last character of the folder name as \"Time\"\n",
    "\n",
    "        # Append the processed DataFrame to the list\n",
    "        dataframes.append(events_df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "full_data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Print the shape of the final DataFrame for verification\n",
    "print(f\"Data successfully processed. Final DataFrame contains {full_data.shape[0]} rows and {full_data.shape[1]} columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use regular expressions to extract clone and replicate information in a vectorized manner\n",
    "full_data[['Clone', 'Replicate']] = full_data['File_Name'].str.extract(\n",
    "    r'_(b|c)(\\d)_', \n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "\n",
    "# Convert Clone to lowercase and Replicate to string to handle potential null values\n",
    "full_data['Clone'] = full_data['Clone'].str.lower()\n",
    "\n",
    "\n",
    "# Conditions to determine the sample type\n",
    "conditions = [\n",
    "    full_data['File_Name'].str.contains(r'_ST', case=False, na=False),  # Staining controls\n",
    "    full_data['File_Name'].str.contains(r'controles', case=False, na=False),  # CCCP controls\n",
    "    full_data['File_Name'].str.contains(r'muestras', case=False, na=False)  # Experimental samples\n",
    "]\n",
    "\n",
    "# Corresponding results for the conditions\n",
    "choices = ['ST', 'Control', 'Sample']\n",
    "\n",
    "# Use np.select to assign Sample_Type based on the conditions\n",
    "full_data['Sample_Type'] = np.select(conditions, choices, default='Unknown')\n",
    "\n",
    "# Assign 'ST' to Clone for staining controls and 'CCCP' for CCCP controls\n",
    "full_data.loc[full_data['Sample_Type'] == 'ST', 'Clone'] = 'ST'\n",
    "full_data.loc[full_data['Sample_Type'] == 'Control', 'Clone'] = 'CCCP'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Time', 'File_Name', and 'Sample_Type' to review the label for each file\n",
    "file_label_by_time = full_data.groupby(['Time', 'File_Name'])['Sample_Type'].unique().reset_index()\n",
    "\n",
    "# Configure pandas to display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Display the entire DataFrame\n",
    "display(file_label_by_time)\n",
    "\n",
    "# Reset pandas display options to avoid global application\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path for the \"data\" folder\n",
    "data_folder_path = os.path.join(main_directory, \"data\")\n",
    "\n",
    "# Check if the \"data\" folder exists; if not, create it\n",
    "if not os.path.exists(data_folder_path):\n",
    "    os.makedirs(data_folder_path)\n",
    "    print(f\"'data' folder created at: {data_folder_path}\")\n",
    "\n",
    "# Define the path and name of the output file within the \"data\" folder\n",
    "output_file_path = os.path.join(data_folder_path, \"processed_data.csv\")\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "full_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"DataFrame successfully exported to: {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
